---
title: "Forecasting Foreign Exchange rates using an ARIMA Model: A case study of USD/KSH rate"
author: "Pamba Gift"
date: "October 2025"
output:
  html_document:
    theme: spacelab
  pdf_document:
---

```{r setup-chunk, include=FALSE}
library(knitr)
opts_chunk$set(message = FALSE, tidy.opts = list(width.cutoff=60), tidy = TRUE)

# Loading libraries
library(tidyverse)
library(ggthemes)
library(data.table)
library(readr)
library(forecast)
library(tseries)
library(pander)
library(cowplot)
library(rsconnect)

# html libraries
# library(thematic)
# library(plotly)
# library(kableExtra)
# library(gtsummary)

# thematic_on(bg = "auto",
#             fg = "auto",
#             accent = "auto",
#             font = "auto")

# Writing a manifest file for upload to Posit
writeManifest()

# ggplot2 theme set
theme_set(theme_clean())


# Loading the forex data 
fx <- read_csv("forexKE2016_2025.csv") |> data.table()

# Filtering USD currency
usd <- fx |> 
  filter(currency == "US DOLLAR")

# Generating Time-Series data structures
usd.ts <- data.table("period" = seq(1, nrow(usd), 1),
                     "date" = usd$date,
                     "rate" = usd$rate)

# Training set
usd_train <- usd.ts[c(1:(0.75*nrow(usd))), 3] |> ts()

# Testing set
usd_test <- usd.ts[c((nrow(usd_train)+1):nrow(usd)), 3] |> ts()

# Fitting the model
model <- auto.arima(usd_train) # ARIMA(1,2,1)

about_model <- model |> summary()
```

# Introduction
This document serves the purpose of explaining to the reader the procedures taken to develop a model that forecasts foreign exchange rates. The data for this project has been sourced [Here](https://www.centralbank.go.ke/forex/). The CBK uploads forex data on `21` currencies. Out of the 21 currencies, this project works with the USD/KES pair. EDA was conducted to the data to discern the possible hypothesis tests and assumptions to be made. Anomalies such as duplicates and wrongly worded characters were identified and dealt with. No missing values were reported. 

The data used to build the model runs from 1st December 2016 upto 13th June 2025. It has ``r nrow(usd)`` observations made on weekdays, excluding public holidays and weekends. All rates are the equivalent value of 1 US Dollar.  


## Descriptive summaries

### Date
```{r, date-summary, echo = FALSE}
usd$date |> summary() |> pander()
```


### Rates

```{r, rate-summary, echo = FALSE}
usd$rate |> summary() |> pander()
```


## Data Visualization

### Time plot

```{r, time-plot, echo = FALSE, fig.align='center', fig.width=7, fig.height=4}
# p <- 
ggplot(data = usd)+
  geom_line(aes(x = date, y = rate), linewidth = 0.55)+
  labs(x = "Date", y = "Rate (Ksh.)",
       title = paste("Forex rates USD/KSH\n1st December 2016 - 13th June 2025"))


# ggplotly(p) |> config(displayModeBar=FALSE)

```

# Methodology
An ARIMA model was chosen to forecast the Forex rates. Fortunately, the `forecast` library has a function that returns an optimal model. This accelerated the workflow and diagnostics. An ARIMA model can have an auto-regressive coefficient(s) or moving average coefficient(s) or both. In addition ,they allow for differencing if the data to be modelled is non-stationary. The optimal model chosen for this data is the `ARIMA(1,2,1)` with an auto-regressive order of `1`, a moving average order of `1` and a differencing order of `2`. The model can be written as;

$$y_{t} = 2.3198{y}_{t-1}-1.6396{y}_{t-2}+0.3198{y}_{t-3}-0.9845{\epsilon}_{t-1}$$


# Results and Findings

## Model building
The first course of action was to split the data into a training (`75%`) and testing set (`25%`). The training set runs from 1st December 2016 upto 25th April 2023 containing ``r length(usd_train)`` observations. The testing set runs from 26th April 2023 upto 13th July 2025 with ``r length(usd_test)`` observations. The training set facilitated model building and diagnostic checks while the testing set was used to evaluate the model's predictive ability. 


## Model validation

### ACF and PACF

This section validates the order used under the ARIMA model `p = 1` and `q = 1`. This is made possible via autocorrelation (ACF) and partial auto-correlation plots. (PACF) The figure below shows the ACF and PACF for the training set.


```{r, acf1, echo = FALSE, fig.align='center'}
Acf <- autoplot(acf(diff(usd_train, differences = 2), plot = FALSE))+
  ggtitle("Autocorrelation Function")

Pacf <- autoplot(pacf(diff(usd_train, differences = 2), plot = FALSE))+
  ggtitle("Partial Autocorrelation Function")

plot_grid(Acf, Pacf, ncol = 1)
```

Both the ACF and PACF tail off gradually as there exists some significant spikes as the lag increases. In this case a mixed model such as an ARMA model would be of use.

### Residual analysis

For an ARIMA model to hold, its residuals should have no autocorrelation (White noise). First, let us visualize the training set's residuals.

```{r, residuals, echo = FALSE, fig.align='center', fig.width=7, fig.height=4}
autoplot(model$residuals)+
  labs(x = "Time", y = "Residuals",
       title = "Residual plot")
```

The residuals appear to be centered around `0.0` with a few extremes. Next, we use the `Ljung-Box Test` to check for independence of residuals.

```{r, Box-L, echo = FALSE}
Box.test(residuals(model), type = "Ljung-Box") |> pander()
```

A p-value of `0.9772` suggests that we fail to reject the null hypothesis of residual independence. 


## Predictive ability

This section analyses forecast ability of our ARIMA model. The table below shows the predictive metrics for the training set;

```{r, prediction-metrics, echo = FALSE}
predictive_metrics <- accuracy(model) 
predictive_metrics |> pander()
```

- Summary
  + The __ME__ (Mean Error) value of ``r predictive_metrics[1]`` indicates that the model has a minimal bias score.
  + A __MAPE__ (Mean Absolute Percentage Error) value of ``r predictive_metrics[5]`` shows that on average ,the model's fitted values deviate by about ``r paste(round(predictive_metrics[5]*100,1),"%")`` from the actual values, which is an acceptable value for forecast models.


Next, we intend to make a forecast 21 days ahead _i.e_ 26th April 2023 upto 23rd May 2023 with weekends and Labour Day excluded. After making the forecast, we once again check the model's predictive metrics, this time, using the first 21 observations of the testing set. The metrics are shown below; 

```{r, fittedVsActual-predictiveAssessment, echo=FALSE}
fcast <- forecast(model, h = 21, level = c(95))
accuracy(fcast$fitted, usd_train[1:21]) |> pander()
```

- Summary
  + The __ME__ is relatively close to 0 ,implying a small prediction bias.
  + The __MAPE__  value of ``r 0.04479`` shows minimal deviation between fitted values and the reported values. 

Below is the table consisting of the forecast values for the period 26th April 2023 upto 25th May 2023 with 95% confidence bounds;


```{r, forecast_table, echo = FALSE, warning=FALSE}
fcast_table <- data.table(
  "Date"=usd$date[c(1586:(1586+20))],
  "Actual_rate"=usd_test[1:21],
  "Forecast_rate"=fcast$mean[1:21],
  "Lower_bound"=fcast$lower[1:21],
  "Upper_bound"=fcast$upper[1:21]
)

fcast_table <- fcast_table |> 
  mutate(Abs_Deviation = abs(Actual_rate-Forecast_rate)) |> 
  relocate(Abs_Deviation, .before = Lower_bound)

fcast_table |> kable()
```

- Summary
  + All of the Actual rates fall within the 95% confidence bounds.
  + The largest deviation ``r max(fcast_table$Abs_Deviation)`` was recorded on ``r fcast_table[fcast_table$Abs_Deviation == max(fcast_table$Abs_Deviation),1] |> pull(Date)``
  + The smallest deviation ``r min(fcast_table$Abs_Deviation)`` was recorded on ``r fcast_table[fcast_table$Abs_Deviation == min(fcast_table$Abs_Deviation),1] |> pull(Date)`` 
  
Now, we plot the model's 21 step ahead forecast.

```{r,forecast-plot, echo = FALSE, fig.align='center', fig.width=6, fig.height=4, message = FALSE}

# p2 <- 
ggplot()+
  geom_line(aes(x = date, y = rate), col = "#000", linewidth = 0.55 ,data = usd[c(1508:1585),])+
  geom_line(aes(x = Date ,y = Upper_bound), col = alpha("#008899", 0.7), linetype = 2, data = fcast_table)+
  geom_line(aes(x = Date ,y = Forecast_rate), col = "#008899", linewidth = 0.55, data = fcast_table)+
  geom_line(aes(x = Date ,y = Lower_bound), col = alpha("#008899", 0.7), linetype = 2, data = fcast_table)+
  labs(x = "Time", y = "Rate (Ksh.)",
       title = paste("Forex rate forecast\nJanuary 2023 - May 2023"))

# ggplotly(p2) |> config(displayModeBar = FALSE)
```

# Conclusion & Recommendations

- Foreign exchange data is non-stationary in nature and therefore, there is need to perform a stationary check before modelling.
- ARIMA models have good predictive metrics that make them suitable for forecasting foreign exchange data.
- Other non-linear models such as GARCH and prophet can be used in place of ARIMA when it comes to forecasting forex data in order to handle their volatility.

# References
- Mong T. U. (2016). Forecasting Foreign Exchange Rate by using ARIMA Model: A Case of VND/USD Exchange Rate. _Research journal of finance and accounting Vol.7(No.12)_ 


