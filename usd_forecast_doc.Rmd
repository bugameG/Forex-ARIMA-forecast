---
title: "Forecasting Foreign Exchange rates using an ARIMA Model: A case study of USD/KSH rate"
author: "Pamba Gift"
date: "October 2025"
output:
  html_document:
    theme: spacelab
---

```{r setup-chunk, include=FALSE}
library(knitr)
opts_chunk$set(message = FALSE, tidy.opts = list(width.cutoff=60), tidy = TRUE)

# Loading libraries
library(tidyverse)
library(ggthemes)
library(data.table)
library(readr)
library(forecast)
library(tseries)
library(pander)
library(cowplot)
library(plotly)
library(DT)
library(rsconnect)

# Writing manifest file for upload to Posit Cloud Connect
writeManifest()

# ggplot2 theme set
theme_set(theme_clean())


# Loading the forex data 
fx <- read_csv("forexKE2016_2025.csv") |> data.table()

# Filtering USD currency
usd <- fx |> 
  filter(currency == "US DOLLAR")

# Generating Time-Series data structures
usd.ts <- data.table("period" = seq(1, nrow(usd), 1),
                     "date" = usd$date,
                     "rate" = usd$rate)

# Training set
usd_train <- usd.ts[c(1:(0.75*nrow(usd))), 3] |> ts()

# Testing set
usd_test <- usd.ts[c((nrow(usd_train)+1):nrow(usd)), 3] |> ts()

# Fitting the model
model <- auto.arima(usd_train) # ARIMA(1,2,1)

about_model <- model |> summary()
```

# Introduction
This document serves the purpose of explaining to the reader the procedures taken to develop a model that forecasts foreign exchange rates. The data for this project has been sourced [Here](https://www.centralbank.go.ke/forex/). The CBK uploads forex data on `21` currencies. Out of the 21 currencies, this project works with the USD/KES pair. EDA was conducted to the data to discern the possible hypothesis tests and assumptions to be made. Anomalies such as duplicates and wrongly worded characters were identified and dealt with. No missing values were reported. 

The data used to build the model runs from 1st December 2016 upto 13th June 2025. It has ``r nrow(usd)`` observations made on weekdays, excluding public holidays and weekends. All rates are the equivalent value of 1 US Dollar.  


## Descriptive summaries

### Date
```{r, date-summary, echo = FALSE}
summary(usd$date) |> pander()
```


### Rates

```{r, rate-summary, echo = FALSE}
summary(usd$rate) |> pander()
```


## Data Visualization

### Time plot

```{r, first_time_plot, echo = FALSE, fig.align='center', fig.width=7, fig.height=4}
usd_plot <- ggplot(data = usd)+
  geom_line(aes(x = date, y = rate), linewidth = 0.55)+
  labs(x = "Date", y = "Rate (Ksh.)",
       title = paste("Forex rates USD/KSH\n1st December 2016 - 13th June 2025"))


ggplotly(usd_plot) |> config(displayModeBar=FALSE)

```

# Methodology
An ARIMA model was chosen to forecast the Forex rates. Fortunately, the `forecast` library has a function that returns an optimal model. This accelerated the workflow and diagnostics. An ARIMA model can have an auto-regressive coefficient(s) or moving average coefficient(s) or both. In addition ,they allow for differencing if the data to be modelled is non-stationary. The optimal model chosen for this data is the `ARIMA(1,2,1)` with an auto-regressive order of `1`, a moving average order of `1` and a differencing order of `2`. Generally an ARIMA model is written as;

$$\Phi(B)(1-B)^{d}y_{t}=\Theta(B)Z_{t}$$
where:

- $B$ is the backshift operator such that $B^1y_t=y_{t-1}$
- $d$ is the level of differencing performed
- $\Phi(B)$ is the autoregressive polynomial 
- $1-\phi_1B-\phi_2B^2-\cdots-\phi_pB^p$ with $\phi_i$ the AR coefficients for $i=1,2,\cdots,p$ 
- $\Theta(B)$ is the moving average polynomial $1-\theta_1B-\theta_2B^2-\cdots-\theta_pB^p$ with $\theta_i$ the MA coefficients for $i=1,2,\cdots,q$
- $Z_t$ is the error term
  


The model has a single AR coefficient of ``r model$coef[1]`` and a single MA coefficient of ``r model$coef[2]``. Plugging the values to the above formula and simplifying, we end up having the model as,

$$ \hat{y_t} = 2.3198y_{t-1} - 1.6396y_{t-2} + 0.3198y_{t-3} + 0.9845Z_{t-1}$$



# Results and Findings

## Model building
The first course of action was to split the data into a training (`75%`) and testing set (`25%`). The training set runs from 1st December 2016 upto 25th April 2023 containing ``r length(usd_train)`` observations. The testing set runs from 26th April 2023 to 13th July 2025 with ``r length(usd_test)`` observations. The training set facilitated model building and diagnostic checks while the testing set was used to evaluate the model's predictive ability. 


## Model validation

### ACF and PACF

This section validates the order used under the ARIMA model `p = 1` and `q = 1`. This is made possible via autocorrelation (ACF) and partial auto-correlation plots. (PACF) The figure below shows the ACF and PACF for the training set.


```{r, acf1, echo = FALSE, fig.align='center'}
usd_acf <- autoplot(acf(diff(usd_train, differences = 2), plot = FALSE))+
  ggtitle("Autocorrelation Function")

usd_pacf <- autoplot(pacf(diff(usd_train, differences = 2), plot = FALSE))+
  ggtitle("Partial Autocorrelation Function")

plot_grid(usd_acf, usd_pacf, ncol = 1)
```

Both the ACF AND PACF tail off gradually as there exists some significant spikes as the lag increases. In this case a mixed model such as an ARMA model would be of use.

### Residual analysis

For an ARIMA model to hold, its residuals should have no autocorrelation (White noise). First, let us visualize the training set's residuals.

```{r, residuals, echo = FALSE, fig.align='center', fig.width=7, fig.height=4}
autoplot(model$residuals)+
  labs(x = "Time", y = "Residuals",
       title = "Residual plot")
```

The residuals appear to be centered around `0.0` with a few extremes. Next, we use the `Ljung-Box Test` to check for independence of residuals.

```{r, Box-L, echo = FALSE}
Box.test(residuals(model), type = "Ljung-Box") |> pander()
```

A p-value of `0.9772` suggests that we fail to reject the null hypothesis of residual independence. 


## Predictive ability

This section analyses forecast ability of our ARIMA model. The table below shows the predictive metrics for the training set;

```{r, prediction-metrics, echo = FALSE}
predictive_metrics <- accuracy(model) 
predictive_metrics |> pander()
```

- Summary
  + The __ME__ (Mean Error) value of ``r predictive_metrics[1]`` indicates that the model has a minimal bias score.
  + A __MAPE__ (Mean Absolute Percentage Error) value of ``r predictive_metrics[5]`` shows that on average ,the model's fitted values deviate by about ``r paste(round(predictive_metrics[5]*100,1),"%")`` from the actual values, which is an acceptable value for forecast models.


Next, we intend to make a forecast 21 days ahead _i.e_ 26th April 2023 o 23rd May 2023 with weekends and Labour Day excluded. After making the forecast, we once again check the model's predictive metrics, this time, using the first 21 observations of the testing set. The metrics are shown below; 

```{r, fittedVsActual-predictiveAssessment, echo=FALSE}
fcast_test <- forecast(model, h = 21, level = c(95))
accuracy(fcast_test$fitted, usd_train[1:21]) |> pander()
```

- Summary
  + The __ME__ is relatively close to 0 ,implying a small prediction bias.
  + The __MAPE__  value of ``r 0.04479`` shows minimal deviation between fitted values and the reported values. 

Below is the table consisting of the forecast values for the period 26th April 2023 upto 25th May 2023 with 95% confidence bounds;


```{r, test_forecast_table, echo = FALSE, warning=FALSE}
fcast_table <- data.table(
  "Date"=usd$date[c(1586:(1586+20))],
  "Actual_rate"=usd_test[1:21],
  "Forecast_rate"=fcast_test$mean[1:21],
  "Lower_bound"=fcast_test$lower[1:21],
  "Upper_bound"=fcast_test$upper[1:21]
)

fcast_table <- fcast_table |> 
  mutate(Abs_Deviation = abs(Actual_rate-Forecast_rate)) |> 
  relocate(Abs_Deviation, .before = Lower_bound)

fcast_table |> kable(col.names = c("date", "actual value (Ksh.)", "fitted value (Ksh.)", "absolute deviation (Ksh.)","lower bound (Ksh.)", "upper bound (Ksh.)"))
```

- Summary
  + All of the Actual rates fall within the 95% confidence bounds.
  + The largest deviation ``r max(fcast_table$Abs_Deviation)`` was recorded on ``r fcast_table[fcast_table$Abs_Deviation == max(fcast_table$Abs_Deviation),1] |> pull(Date)``
  + The smallest deviation ``r min(fcast_table$Abs_Deviation)`` was recorded on ``r fcast_table[fcast_table$Abs_Deviation == min(fcast_table$Abs_Deviation),1] |> pull(Date)`` 
  
  
## Forecasting

Now it is time to put the model into use. To do this we generate a 35-business day ahead forecast from 16th June 2025 to 1st August 2025. The forecast values are shown in the table below 

```{r, final_forecast_table, echo = FALSE, fig.align='center', fig.width=6, fig.height=4, message = FALSE}

# Forecast dates 
start.date <- ymd("2025-06-16")
all.dates <- seq.Date(from = start.date, 
                      by = "day", length.out = 47)

fcast_dates <- all.dates[!weekdays(all.dates) %in% c("Saturday","Sunday")]


# Refitting the training model to capture the whole dataset 
model2 <- Arima(ts(usd$rate), model = model)

# Forecast values
fcast <- forecast(model2, h = 35, level = 95)

# Forecast table for ggplot
fcast_table2 <- data.table(
  "date"=c(usd$date, fcast_dates),
  "rates"=c(usd$rate, fcast$mean),
  "lower_bound"=c(rep(NA, 2114), fcast$lower),
  "upper_bound"=c(rep(NA, 2114), fcast$upper)
)

fcast_table2 |> 
  datatable(style = "bootstrap4", 
            colnames = c("date", "rate (Ksh.)", "lower bound (Ksh.)", "upper bound (Ksh.)"))
```

The figure below captures the ARIMA forecast with 95% confidence bounds.

```{r, last_time_plot, echo=FALSE, fig.align='center', fig.width=7, fig.height=4}
usd_fcast_plot <-
ggplot()+
  geom_line(aes(x = date, y = rates), col = "#000", linewidth = 0.55 ,data = fcast_table2)+
  geom_line(aes(x = date ,y = lower_bound), col = alpha("#008899", 0.5), linetype = 2, data = fcast_table2[c(2115:2149),])+
  geom_line(aes(x = date ,y = rates), col = "#008899", linewidth = 0.55, data = fcast_table2[c(2115:2149),])+
  geom_line(aes(x = date ,y = upper_bound), col = alpha("#008899", 0.5), linetype = 2, data = fcast_table2[c(2115:2149),])+
  labs(x = "Time", y = "Rate (Ksh.)",
       title = paste("Forex rate forecast\n1st December 2016 - 1st August 2025"))

ggplotly(usd_fcast_plot) |> config(displayModeBar = FALSE)

```



# Conclusion & Recommendations

- Foreign exchange data is non-stationary in nature and therefore, there is need to perform a stationary check before modelling.
- ARIMA models have good predictive metrics that make them suitable for forecasting foreign exchange data.
- Other non-linear models such as GARCH and prophet can be used in place of ARIMA when it comes to forecasting forex data in order to handle their volatility.

# References
- Mong T. U. (2016). Forecasting Foreign Exchange Rate by using ARIMA Model: A Case of VND/USD Exchange Rate. _Research journal of finance and accounting Vol.7(No.12)_ 


